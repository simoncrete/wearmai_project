{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef9835a0-a7ea-4b30-b0eb-d017709b302b",
   "metadata": {},
   "source": [
    "### Train on COCO2014 dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6793c18-61fc-45fb-bec9-f08fe63c5181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: train.py [-h] --name NAME [--time_to_run TIME_TO_RUN] [--resume]\n",
      "                [--num_workers NUM_WORKERS] [--pin_memory | --no_pin_memory]\n",
      "                [--log_dir LOG_DIR] [--checkpoint CHECKPOINT]\n",
      "                [--from_json FROM_JSON]\n",
      "                [--pretrained_checkpoint PRETRAINED_CHECKPOINT]\n",
      "                [--num_epochs NUM_EPOCHS] [--lr LR] [--batch_size BATCH_SIZE]\n",
      "                [--summary_steps SUMMARY_STEPS] [--test_steps TEST_STEPS]\n",
      "                [--checkpoint_steps CHECKPOINT_STEPS] [--img_res IMG_RES]\n",
      "                [--rot_factor ROT_FACTOR] [--noise_factor NOISE_FACTOR]\n",
      "                [--scale_factor SCALE_FACTOR] [--ignore_3d]\n",
      "                [--shape_loss_weight SHAPE_LOSS_WEIGHT]\n",
      "                [--keypoint_loss_weight KEYPOINT_LOSS_WEIGHT]\n",
      "                [--pose_loss_weight POSE_LOSS_WEIGHT]\n",
      "                [--beta_loss_weight BETA_LOSS_WEIGHT]\n",
      "                [--openpose_train_weight OPENPOSE_TRAIN_WEIGHT]\n",
      "                [--gt_train_weight GT_TRAIN_WEIGHT] [--run_smplify]\n",
      "                [--smplify_threshold SMPLIFY_THRESHOLD]\n",
      "                [--num_smplify_iters NUM_SMPLIFY_ITERS]\n",
      "                [--shuffle_train | --no_shuffle_train]\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "\n",
      "Required:\n",
      "  --name NAME           Name of the experiment\n",
      "\n",
      "General:\n",
      "  --time_to_run TIME_TO_RUN\n",
      "                        Total time to run in seconds. Used for training in\n",
      "                        environments with timing constraints\n",
      "  --resume              Resume from checkpoint (Use latest checkpoint by\n",
      "                        default\n",
      "  --num_workers NUM_WORKERS\n",
      "                        Number of processes used for data loading\n",
      "  --pin_memory\n",
      "  --no_pin_memory\n",
      "\n",
      "io:\n",
      "  --log_dir LOG_DIR     Directory to store logs\n",
      "  --checkpoint CHECKPOINT\n",
      "                        Path to checkpoint\n",
      "  --from_json FROM_JSON\n",
      "                        Load options from json file instead of the command\n",
      "                        line\n",
      "  --pretrained_checkpoint PRETRAINED_CHECKPOINT\n",
      "                        Load a pretrained checkpoint at the beginning training\n",
      "\n",
      "Training Options:\n",
      "  --num_epochs NUM_EPOCHS\n",
      "                        Total number of training epochs\n",
      "  --lr LR               Learning rate\n",
      "  --batch_size BATCH_SIZE\n",
      "                        Batch size\n",
      "  --summary_steps SUMMARY_STEPS\n",
      "                        Summary saving frequency\n",
      "  --test_steps TEST_STEPS\n",
      "                        Testing frequency during training\n",
      "  --checkpoint_steps CHECKPOINT_STEPS\n",
      "                        Checkpoint saving frequency\n",
      "  --img_res IMG_RES     Rescale bounding boxes to size [img_res, img_res]\n",
      "                        before feeding them in the network\n",
      "  --rot_factor ROT_FACTOR\n",
      "                        Random rotation in the range [-rot_factor, rot_factor]\n",
      "  --noise_factor NOISE_FACTOR\n",
      "                        Randomly multiply pixel values with factor in the\n",
      "                        range [1-noise_factor, 1+noise_factor]\n",
      "  --scale_factor SCALE_FACTOR\n",
      "                        Rescale bounding boxes by a factor of\n",
      "                        [1-scale_factor,1+scale_factor]\n",
      "  --ignore_3d           Ignore GT 3D data (for unpaired experiments\n",
      "  --shape_loss_weight SHAPE_LOSS_WEIGHT\n",
      "                        Weight of per-vertex loss\n",
      "  --keypoint_loss_weight KEYPOINT_LOSS_WEIGHT\n",
      "                        Weight of 2D and 3D keypoint loss\n",
      "  --pose_loss_weight POSE_LOSS_WEIGHT\n",
      "                        Weight of SMPL pose loss\n",
      "  --beta_loss_weight BETA_LOSS_WEIGHT\n",
      "                        Weight of SMPL betas loss\n",
      "  --openpose_train_weight OPENPOSE_TRAIN_WEIGHT\n",
      "                        Weight for OpenPose keypoints during training\n",
      "  --gt_train_weight GT_TRAIN_WEIGHT\n",
      "                        Weight for GT keypoints during training\n",
      "  --run_smplify         Run SMPLify during training\n",
      "  --smplify_threshold SMPLIFY_THRESHOLD\n",
      "                        Threshold for ignoring SMPLify fits during training\n",
      "  --num_smplify_iters NUM_SMPLIFY_ITERS\n",
      "                        Number of SMPLify iterations\n",
      "  --shuffle_train       Shuffle training data\n",
      "  --no_shuffle_train    Don't shuffle training data\n"
     ]
    }
   ],
   "source": [
    "!python3 train.py --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aede9c29-aafc-4424-910b-8b944f4d2537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/simon/Desktop/SPIN/train.py\", line 6, in <module>\n",
      "    trainer = Trainer(options)\n",
      "  File \"/home/simon/Desktop/SPIN/utils/base_trainer.py\", line 21, in __init__\n",
      "    self.init_fn()\n",
      "  File \"/home/simon/Desktop/SPIN/train/trainer.py\", line 24, in init_fn\n",
      "    self.model = hmr(config.SMPL_MEAN_PARAMS, pretrained=True).to(self.device)\n",
      "  File \"/home/simon/Desktop/SPIN/models/hmr.py\", line 159, in hmr\n",
      "    model = HMR(Bottleneck, [3, 4, 6, 3],  smpl_mean_params, **kwargs)\n",
      "  File \"/home/simon/Desktop/SPIN/models/hmr.py\", line 81, in __init__\n",
      "    m.weight.data.normal_(0, math.sqrt(2. / n))\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "#Train on just COCO. \n",
    "#Batch size 64--> GPU memory issue\n",
    "#Change COCO root in config.py, change mixed_dataset.py to only look for COCO, change conversion error in torchgeometry library\n",
    "!python3 train.py --name train_example_COCO2014 --pretrained_checkpoint=data/model_checkpoint.pt --run_smplify --num_epochs 10 --batch_size 32 --num_workers 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111e2e72-4dd0-402a-9c7d-2e4b87aee4fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d785fca-189d-4e92-a846-d61e15eb1a0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd96806-d92d-4398-ba66-bb512a27d737",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
